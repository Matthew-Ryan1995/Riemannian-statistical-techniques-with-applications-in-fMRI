---
title: "The pseudo-R2 statistic"
output: html_document
date: "2022-12-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# The pseudo-$R^2$ statistic

From MDMR we have a matrix of disimilarities $D_{n \times n}$ and a matrix of predictors $\tilde{X}_{n \times p_0}$ (first column identically 1).  Considering Gower matrix
\[
  G = \left(I - \frac{1}n 11^T\right) A \left(I - \frac{1}n 11^T\right)\,, 
\]
where $A = \left[ -\frac{1}{2} d_{ij}^2 \right]$, and the projection matrix $H = \tilde{X}(\tilde{X}^T\tilde{X})^{-1}\tilde{X}^T$, the pseudo-$R^2$ statistic is
\[
  \tilde{R}^2 = \frac{\mathrm{Tr}(HG)}{\mathrm{Tr}(G)}\, .
\]
Throughout, let $J = \left(I - \frac{1}n 11^T\right)$ to simplify notation.

# Euclidean example

Suppose
\[
  Y_{n \times q} = X_{n \times p} B_{p \times q} + E_{n \times q}
\]
where $E_i^T \sim N_q(0, qI)$ independently for each $i = 1, 2, \dots, n$ ($E_i^T$ is the $i^{th}$ row of $E$).  Thus, $Y$ is a $q$-variate response variable generated by a $p$-dimensional subspace.  Note that $X$ denotes the true underlying predictors (first column identically 1), constant yet unknown. $\tilde{X}_{n \times p_0}$ denotes the predictors in our model that we **know**.  Throughout, suppose $p < q$.

The Gower matrix using the Euclidean distance can be written
\[
  G = J Y Y^T J\, .
\]
Thus, we can start to ask about the expected value of the $\tilde{R}^2$ statistic.  First note that
$$
  \begin{aligned}
    E\left[ Y Y^T \right] & = E\left[ (X B + E) (X B + E)^T \right] \\
      & = XBB^TX^T + E[E]B^TX^T + XBE[E^T] + E[EE^T] \\
      & = XBB^TX^T + E[EE^T]\, .
  \end{aligned}
$$
Considering the $(ij)^{th}$ element of $EE^T$, we see
\[
  \left[ EE^T \right]_{ij} = \sum_{k = 1}^q e_{ik}e_{jk}\, ,
\]
so
\[
  E\left[\left[ EE^T \right]_{ij}\right] = 
    \begin{cases}
      q & \text{ if } i = j\, ,\\
      0 & \text{ else.}
    \end{cases}
\]
Hence,
\[
   E\left[ Y Y^T \right] = XBB^TX^T + q I_{n \times n}\,.
\]
Now, consider the denominator of $\tilde{R}^2$.  We see that
$$
  \begin{aligned}
    E\left[ \mathrm{Tr}(G) \right] &= \mathrm{Tr}\left( E\left[ G \right]\right) \\
      & = \mathrm{Tr}\left( JE\left[ YY^T \right]J\right) \\
      & = \mathrm{Tr}\left( J\left[ XBB^TX^T + q I \right]J\right) \\
      & = q \mathrm{Tr}(J) + \mathrm{Tr}(JXBB^TX^T J^T) \\
      & = q(n-1) + \left\| JXB \right\|_{F}^2\, ,
  \end{aligned}
$$
where $\left\| \cdot \right\|_{F}^2$ is the squared Frobenius norm, and the last two lines follow because:

1. $J$ is a projection matrix, and hence symmetric and idempotent,
2. $\mathrm{Tr}(J) = n-1$.

In a similar manner, we find that
\[
  E\left[ \mathrm{Tr}(HG) \right] = q(p_0 - 1) + \left\| HJXB \right\|_{F}^2\, ,
\]
because $\mathrm{Tr}(HJ) = p_0 - 1$.  Thus, the first order Taylor approximation gives
$$
  \begin{aligned}
    E\left[ \tilde{R}^2 \right] & \approx \frac{E\left[ \mathrm{Tr}(HG) \right]}{E\left[ \mathrm{Tr}(G) \right]} \\
      & = \frac{q(p_0 - 1) + \left\| HJXB \right\|_{F}^2}{q(n-1) + \left\| JXB \right\|_{F}^2}\, .
  \end{aligned}
$$

## Notes

1. Through numerical simulation, it seems this first order Taylor approximation is true up to about 4 decimal places.
2. I started to look at the second-order Taylor, but I think that gets me into Kronecker products and variances of matrices that I simply don't want to deal with.
3. I strongly suspect that $\left\| HJXB \right\|_{F}^2$ and $\left\| JXB \right\|_{F}^2$ have semi-nice forms with respect to $p$ and $p_0$.
4. Simulation seems to suggest that $\left\| HJXB \right\|_{F}^2$ and $\left\| JXB \right\|_{F}^2$ are closely related, in fact when $p = p_0$ they are equal.
5. These speculations assume that $\tilde{X}$ is a submatrix of $X$.

